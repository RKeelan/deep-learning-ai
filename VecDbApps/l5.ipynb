{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from deepface import DeepFace\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "from DLAIUtils import Utils\n",
    "\n",
    "\n",
    "import contextlib\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "utils = Utils()\n",
    "PINECONE_API_KEY = utils.get_pinecone_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "#!wget -q --show-progress -O family_photos.zip \"https://www.dropbox.com/scl/fi/yg0f2ynbzzd2q4nsweti5/family_photos.zip?rlkey=00oeuiii3jgapz2b1bfj0vzys&dl=0\"\n",
    "#!unzip -q family_photos.zip\n",
    "\n",
    "def show_img(f):\n",
    "    img = plt.imread(f)\n",
    "    plt.figure(figsize=(4,3))\n",
    "    plt.imshow(img)\n",
    "\n",
    "show_img('family/dad/P06260_face5.jpg')\n",
    "show_img('family/mom/P04407_face2.jpg')\n",
    "show_img('family/child/P04414_face1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setuo Pinceone\n",
    "MODEL = \"Facenet\"\n",
    "INDEX_NAME = utils.create_dlai_index_name('dl-ai')\n",
    "\n",
    "pinecone = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Embeddings Using DeepFace\n",
    "def generate_vectors():\n",
    "    VECTOR_FILE = \"./vectors.vec\"\n",
    "    with contextlib.suppress(FileNotFoundError):\n",
    "        os.remove(VECTOR_FILE)\n",
    "    with open(VECTOR_FILE, \"w\") as f:\n",
    "        for person in [\"mom\", \"dad\", \"child\"]:\n",
    "            files = glob.glob(f'family/{person}/*')\n",
    "            for file in tqdm(files):\n",
    "                try:\n",
    "                    embedding = DeepFace.represent(img_path=file, model_name=MODEL, enforce_detection=False)[0]['embedding']\n",
    "                    f.write(f'{person}:{os.papth.basename(file)}:{embedding}\\n')\n",
    "                except (ValueError, UnboundLocalError, AttributeError) as e:\n",
    "                    print(e)\n",
    "generate_vectors()\n",
    "!head -10 vectors.vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Data of Images\n",
    "def gen_tsne_df(person, perplexity):\n",
    "    vectors = []\n",
    "    with open('./vectors.vec', 'r') as f:\n",
    "        for line in tqdm(f):\n",
    "            p, orig_img, v = line.split(':')\n",
    "            if person == p:\n",
    "                vectors.append(eval(v))\n",
    "    pca = PCA(n_components=8)\n",
    "    tsne = TSNE(2, perplexity=perplexity, random_state=0, n_iter=1000, verbose=0, metric='euclidean', learning_rate=75)\n",
    "    print(f\"transform {len(vectors)} vectors\")\n",
    "    pca_transform = pca.fit_transform(vectors)\n",
    "    embeddings2d = tsne.fit_transform(pca_transform)\n",
    "    return pd.DataFrame({'x':embeddings2d[:,0], 'y':embeddings2d[:,1]})\n",
    "\n",
    "def plot_tsne(perplexity, model):\n",
    "    (_, ax) = plt.subplots(1, 3, figsize=(8, 5))\n",
    "    plt.grid(color='#EAEAEB', linewidth=0.5)\n",
    "    ax.spines['top'].set_color(None)\n",
    "    ax.spines['right'].set_color(None)\n",
    "    ax.spines['left'].set_color('#2B2F30')\n",
    "    ax.spines['bottom'].set_color('#2B2F30')\n",
    "    colormap = {'dad':'#ee8933', 'child':'#4fad5b', 'mom':'#4c93db'}\n",
    "\n",
    "    for person in colormap:\n",
    "        embeddingsdf = gen_tsne_df(person, perplexity)\n",
    "        ax.scatter(embeddingsdf.x, embeddingsdf.y, alpha=.5, \n",
    "                   label=person, color=colormap[person])\n",
    "    plt.title(f'Scatter plot of faces using {model}', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.suptitle(f't-SNE [perplexity={perplexity}]', y=0.92, fontsize=13)\n",
    "    plt.legend(loc='best', frameon=True)\n",
    "    plt.show()\n",
    "\n",
    "plot_tsne(44, 'facenet')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the Embeddings in Pinecone\n",
    "if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n",
    "  pinecone.delete_index(INDEX_NAME)\n",
    "pinecone.create_index(name=INDEX_NAME, dimension=128, metric='cosine',\n",
    "  spec=ServerlessSpec(cloud='aws', region='us-west-2'))\n",
    "\n",
    "index = pinecone.Index(INDEX_NAME)\n",
    "\n",
    "def store_vectors():\n",
    "  with open(\"vectors.vec\", \"r\") as f:\n",
    "    for line in tqdm(f):\n",
    "        person, file, vec = line.split(':')\n",
    "        index.upsert([(f'{person}-{file}', eval(vec), {\"person\":person, \"file\":file})])\n",
    "store_vectors()\n",
    "\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Similarity Scores\n",
    "def test(vec_groups, parent, child):\n",
    "    index = pinecone.Index(INDEX_NAME)\n",
    "    parent_vecs = vec_groups[parent]\n",
    "    K = 10\n",
    "    SAMPLE_SIZE = 10\n",
    "    sum = 0\n",
    "    for i in tqdm(range(0, SAMPLE_SIZE)):\n",
    "        query_response = index.query(\n",
    "            top_k=K,\n",
    "            vector = parent_vecs[i],\n",
    "            filter={\n",
    "                \"person\": {\"$eq\": child}\n",
    "            }\n",
    "        )\n",
    "        for row in query_response:\n",
    "            sum += row['score']\n",
    "    print(f\"\\n\\n{parent} AVG: {sum/(SAMPLE_SIZE*K)}\")\n",
    "\n",
    "def compute_scores():\n",
    "    index = pinecone.Index(INDEX_NAME)\n",
    "    vec_groups = {\"dad\":[], \"mom\":[], \"child\":[]}\n",
    "    with open(\"vectors.vec\", \"r\") as f:\n",
    "        for line in f:\n",
    "            person, file, vec = line.split(':')\n",
    "            vec_groups[person].append(eval(vec))\n",
    "    print(f\"DAD {'-'*20}\")\n",
    "    test(vec_groups, \"dad\", \"child\")\n",
    "    print(f\"MOM {'-'*20}\")\n",
    "    test(vec_groups, \"mom\", \"child\")\n",
    "\n",
    "compute_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Mathching Images\n",
    "child_base = 'family/child/P06310_face1.jpg'\n",
    "show_img(child_base)\n",
    "\n",
    "# Now find the closest image of Dad\n",
    "embedding = DeepFace.represent(child_base, model_name=MODEL, enforce_detection=False)[0]['embedding']\n",
    "print(embedding)\n",
    "\n",
    "query_response = index.query(\n",
    "    top_k=1,\n",
    "    vector=embedding,\n",
    "    filter={\n",
    "        \"person\": {\"$eq\": \"dad\"}\n",
    "    },\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(query_response)\n",
    "photo = query_response['matches'][0]['metadata']['file']\n",
    "show_img(f'family/dad/{photo}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
