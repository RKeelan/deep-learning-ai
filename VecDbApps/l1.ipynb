{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from DLAIUtils import Utils\n",
    "import DLAIUtils\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5dcb1eeb0894afeb30a64d0842f313d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/35.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c84aaa356d4c6fab30044791b16a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/404290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'questions': [{'id': [207550, 351729],\n",
       "   'text': ['What is the truth of life?', \"What's the evil truth of life?\"]},\n",
       "  {'id': [33183, 351730],\n",
       "   'text': ['Which is the best smartphone under 20K in India?',\n",
       "    'Which is the best smartphone with in 20k in India?']},\n",
       "  {'id': [351731, 351732],\n",
       "   'text': ['Steps taken by Canadian government to improve literacy rate?',\n",
       "    'Can I send homemade herbal hair oil from India to US via postal or private courier services?']},\n",
       "  {'id': [37799, 94186],\n",
       "   'text': ['What is a good way to lose 30 pounds in 2 months?',\n",
       "    'What can I do to lose 30 pounds in 2 months?']},\n",
       "  {'id': [351733, 351734],\n",
       "   'text': ['Which of the following most accurately describes the translation of the graph y = (x+3)^2 -2 to the graph of y = (x -2)^2 +2?',\n",
       "    'How do you graph x + 2y = -2?']}],\n",
       " 'is_duplicate': [False, True, False, True, False]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"quora\", split='train[240000:290000]')\n",
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does the lie rank in human interaction imperfection?\n",
      "Why do I feel weak after masturbation?\n",
      "How do I best way to get over an ex?\n",
      "What happens after clearing the UPSC examination?\n",
      "How do you define love in China?\n",
      "--------------------------------------------------\n",
      "Number of questions: 88919\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "for record in dataset['questions']:\n",
    "    questions.extend(record['text'])\n",
    "question = list(set(questions))\n",
    "print('\\n'.join(question[:5]))\n",
    "print('-'*50)\n",
    "print(f\"Number of questions: {len(question)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, no cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7899ec65328e4460b11bb78a478a27ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61771e77ef94419c8335db7897ef6097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad39d3f976f41ebbb9f639319c66f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d597ca459f4d4f23b1296d7a7e597c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97bf829f73344e98609accef663c6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b62eb63d5ac49a198f5baa21cfac974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd6597862834b77ba49636105bf7990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bac59279314975ba6fea8326d1826f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247b3ca6bcaa421a89b1cf7ec858d189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1ad88094024b01be28df1f02e2b12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285d5ef2e47d4fae894b6c75d040d055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device != 'cuda':\n",
    "    print(\"Sorry, no cuda.\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'which city is the most populated in the world?'\n",
    "xq = model.encode(query)\n",
    "xq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "PineconeConfigurationError",
     "evalue": "You haven't specified an Api-Key.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPineconeConfigurationError\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m utils \u001b[38;5;241m=\u001b[39m Utils()\n\u001b[0;32m      2\u001b[0m PINECONE_API_KEY \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mget_pinecone_api_key()\n\u001b[1;32m----> 3\u001b[0m pinecone \u001b[38;5;241m=\u001b[39m \u001b[43mPinecone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPINECONE_API_KEY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m INDEX_NAME \u001b[38;5;241m=\u001b[39m Utils\u001b[38;5;241m.\u001b[39mcreate_dlai_index_name(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdl-ai\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m INDEX_NAME \u001b[38;5;129;01min\u001b[39;00m [index\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m pinecone\u001b[38;5;241m.\u001b[39mlist_indexes()]:\n",
      "File \u001b[1;32mc:\\Users\\RKeelan\\Src\\DeepLearningAi\\env\\lib\\site-packages\\pinecone\\control\\pinecone.py:95\u001b[0m, in \u001b[0;36mPinecone.__init__\u001b[1;34m(self, api_key, host, config, additional_headers, pool_threads, index_api, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m configKwarg\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m PineconeConfig\u001b[38;5;241m.\u001b[39mbuild(api_key\u001b[38;5;241m=\u001b[39mapi_key, host\u001b[38;5;241m=\u001b[39mhost, additional_headers\u001b[38;5;241m=\u001b[39madditional_headers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool_threads \u001b[38;5;241m=\u001b[39m pool_threads\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_api:\n",
      "File \u001b[1;32mc:\\Users\\RKeelan\\Src\\DeepLearningAi\\env\\lib\\site-packages\\pinecone\\config\\pinecone_config.py:24\u001b[0m, in \u001b[0;36mPineconeConfig.build\u001b[1;34m(api_key, host, additional_headers, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     22\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIgnoring PINECONE_ADDITIONAL_HEADERS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ConfigBuilder\u001b[38;5;241m.\u001b[39mbuild(api_key\u001b[38;5;241m=\u001b[39mapi_key, host\u001b[38;5;241m=\u001b[39mhost, additional_headers\u001b[38;5;241m=\u001b[39madditional_headers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\RKeelan\\Src\\DeepLearningAi\\env\\lib\\site-packages\\pinecone\\config\\config.py:45\u001b[0m, in \u001b[0;36mConfigBuilder.build\u001b[1;34m(api_key, host, openapi_config, additional_headers, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m host \u001b[38;5;241m=\u001b[39m normalize_host(host)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api_key:\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PineconeConfigurationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou haven\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt specified an Api-Key.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m host:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PineconeConfigurationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou haven\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt specified a host.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mPineconeConfigurationError\u001b[0m: You haven't specified an Api-Key."
     ]
    }
   ],
   "source": [
    "utils = Utils()\n",
    "PINECONE_API_KEY = utils.get_pinecone_api_key()\n",
    "pinecone = Pinecone(api_key=PINECONE_API_KEY)\n",
    "INDEX_NAME = Utils.create_dlai_index_name('dl-ai')\n",
    "\n",
    "if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n",
    "    pinecone.delete_index(INDEX_NAME)\n",
    "print(INDEX_NAME)\n",
    "pinecone.create_index(\n",
    "    name=INDEX_NAME,\n",
    "    dimension=model.get_sentence_embedding_dimension(),\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(cloud='aws', region='us-west-2')\n",
    ")\n",
    "# Things stop working here becuase I don't actually have an OpenAI API key\n",
    "index = pinecone.Index(INDEX_NAME)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings and Upsert to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'questiosn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m questions \u001b[38;5;241m=\u001b[39m question[:vector_limt]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mquestiosn\u001b[49m), batch_size)):\n\u001b[0;32m      8\u001b[0m     i_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(i\u001b[38;5;241m+\u001b[39mbatch_size, \u001b[38;5;28mlen\u001b[39m(questions))                   \u001b[38;5;66;03m# End of the batch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i, i_end)]                     \u001b[38;5;66;03m# Create batch IDs\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'questiosn' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "vector_limt=10000\n",
    "questions = question[:vector_limt]\n",
    "\n",
    "import json\n",
    "\n",
    "for i in tqdm(range(0, len(questiosn), batch_size)):\n",
    "    i_end = min(i+batch_size, len(questions))                   # End of the batch\n",
    "    ids = [str(x) for x in range(i, i_end)]                     # Create batch IDs\n",
    "    metadata = [{'text': text} for text in questions[i:i_end]]  # Create metadata batch\n",
    "    xc = model.encode([questions[i:i_end]])                     # Create embeddings\n",
    "    records = zip(ids, xc, metadata)                            # Zip the batch\n",
    "    index.upsert(vectors=records)                              # Upsert the batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Your Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small helper fucntion so we can repeat queries later\n",
    "def run_query(query):\n",
    "    embedding = model.encode(query).tolist()\n",
    "    results = index.querh(top_k=10, vector=embedding, include_metadata=True, include_values=False)\n",
    "    for result in results['matches']:\n",
    "        print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")\n",
    "\n",
    "run_query(\"Which city has the highest population in the world?\")\n",
    "query = \"How do I make chocolate cake?\"\n",
    "run_query(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
