{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1093eaec",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'env (Python 3.9.18)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/RKeelan/Src/DeepLearningAI/env/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from helper import get_openai_api_key\n",
    "openai_api_key = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcee863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11614ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f98a0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a chatbot.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce34da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the completion request with the tool usage\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        # system prompt: always included in the context window \n",
    "        {\"role\": \"system\", \"content\": system_prompt}, \n",
    "        # chat history (evolves over time)\n",
    "        {\"role\": \"user\", \"content\": \"What is my name?\"}, \n",
    "    ]\n",
    ")\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2ce7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_memory = {\"human\": \"Name: Bob\"}\n",
    "system_prompt = \"You are a chatbot. \" \\\n",
    "+ \"You have a section of your context called [MEMORY] \" \\\n",
    "+ \"that contains information relevant to your conversation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0163d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        # system prompt \n",
    "        {\"role\": \"system\", \"content\": system_prompt + \"[MEMORY]\\n\" + json.dumps(agent_memory)},\n",
    "        # chat history \n",
    "        {\"role\": \"user\", \"content\": \"What is my name?\"},\n",
    "    ],\n",
    ")\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea6e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_memory = {\"human\": \"\", \"agent\": \"\"}\n",
    "\n",
    "def core_memory_save(section: str, memory: str): \n",
    "    agent_memory[section] += '\\n' \n",
    "    agent_memory[section] += memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c11232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tool description \n",
    "core_memory_save_description = \"Save important information about you,\" \\\n",
    "+ \"the agent or the human you are chatting with.\"\n",
    "\n",
    "# arguments into the tool (generated by the LLM)\n",
    "# defines what the agent must generate to input into the tool \n",
    "core_memory_save_properties = \\\n",
    "{\n",
    "    # arg 1: section of memory to edit\n",
    "    \"section\": {\n",
    "        \"type\": \"string\",\n",
    "        \"enum\": [\"human\", \"agent\"],\n",
    "        \"description\": \"Must be either 'human' \" \\\n",
    "        + \"(to save information about the human) or 'agent'\" \\\n",
    "        + \"(to save information about yourself)\",            \n",
    "    },\n",
    "    # arg 2: memory to save\n",
    "    \"memory\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"Memory to save in the section\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# tool schema (passed to OpenAI)\n",
    "core_memory_save_metadata = \\\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"core_memory_save\",\n",
    "            \"description\": core_memory_save_description,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": core_memory_save_properties,\n",
    "                \"required\": [\"section\", \"memory\"],\n",
    "            },\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83efe493",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "agent_memory = {\"human\": \"\"}\n",
    "system_prompt = \"You are a chatbot. \" \\\n",
    "+ \"You have a section of your context called [MEMORY] \" \\\n",
    "+ \"that contains information relevant to your conversation\"\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        # system prompt \n",
    "        {\"role\": \"system\", \"content\": system_prompt}, \n",
    "        # memory \n",
    "        {\"role\": \"system\", \"content\": \"[MEMORY]\\n\" + json.dumps(agent_memory)},\n",
    "        # chat history \n",
    "        {\"role\": \"user\", \"content\": \"My name is Bob\"},\n",
    "    ],\n",
    "    # tool schemas \n",
    "    tools=[core_memory_save_metadata]\n",
    ")\n",
    "response = chat_completion.choices[0]\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afd50cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = json.loads(response.message.tool_calls[0].function.arguments)\n",
    "arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba41f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function with the specified arguments \n",
    "core_memory_save(**arguments)\n",
    "agent_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb9d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        # system prompt \n",
    "        {\"role\": \"system\", \"content\": system_prompt}, \n",
    "        # memory \n",
    "        {\"role\": \"system\", \"content\": \"[MEMORY]\\n\" + json.dumps(agent_memory)},\n",
    "        # chat history \n",
    "        {\"role\": \"user\", \"content\": \"what is my name\"},\n",
    "    ],\n",
    "    tools=[core_memory_save_metadata]\n",
    ")\n",
    "response = chat_completion.choices[0]\n",
    "response.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21764823",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_memory = {\"human\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_os = system_prompt \\\n",
    "+ \"\\n. You must either call a tool (core_memory_save) or\" \\\n",
    "+ \"write a response to the user. \" \\\n",
    "+ \"Do not take the same actions multiple times!\" \\\n",
    "+ \"When you learn new information, make sure to always\" \\\n",
    "+ \"call the core_memory_save tool.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6210a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_step(user_message, chat_history = []): \n",
    "\n",
    "    # prefix messages with system prompt and memory\n",
    "    messages = [\n",
    "        # system prompt \n",
    "        {\"role\": \"system\", \"content\": system_prompt_os}, \n",
    "        # memory\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"[MEMORY]\\n\" + json.dumps(agent_memory)\n",
    "        },\n",
    "    ] \n",
    "\n",
    "    # append the chat history \n",
    "    messages += chat_history\n",
    "    \n",
    "\n",
    "    # append the most recent message\n",
    "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    # agentic loop \n",
    "    while True: \n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=[core_memory_save_metadata]\n",
    "        )\n",
    "        response = chat_completion.choices[0]\n",
    "\n",
    "        # update the messages with the agent's response \n",
    "        messages.append(response.message)\n",
    "\n",
    "        # if NOT calling a tool (responding to the user), return \n",
    "        if not response.message.tool_calls: \n",
    "            messages.append({\n",
    "                \"role\": \"assistant\", \n",
    "                \"content\": response.message.content\n",
    "            })\n",
    "            return response.message.content\n",
    "\n",
    "        # if calling a tool, execute the tool\n",
    "        if response.message.tool_calls: \n",
    "            print(\"TOOL CALL:\", response.message.tool_calls[0].function)\n",
    "\n",
    "            # add the tool call response to the message history \n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": response.message.tool_calls[0].id,\n",
    "                \"name\": \"core_memory_save\", \"content\": f\"Updated memory: {json.dumps(agent_memory)}\"\n",
    "            })\n",
    "\n",
    "            # parse the arguments from the LLM function call\n",
    "            arguments = json.loads(response.message.tool_calls[0].function.arguments)\n",
    "\n",
    "            # run the function with the specified arguments\n",
    "            core_memory_save(**arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dce40e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_step(\"my name is bob.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
