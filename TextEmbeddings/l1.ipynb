{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import authenticate\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "\n",
    "\n",
    "PROJECT_ID = \"stately-command-416115\"\n",
    "credentials = authenticate()\n",
    "REGION = 'us-central1'\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=REGION, credentials=credentials)\n",
    "embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
    "embedding = embedding_model.get_embeddings([\"life\"])\n",
    "\n",
    "vector = embedding[0].vector\n",
    "print(f\"Length = {len(vector)}\")\n",
    "print(vector[:10])\n",
    "\n",
    "embedding = embedding_model.get_embeddings([\"What is the meaning of life?\"])\n",
    "vector = embedding[0].vector\n",
    "print(f\"Length = {len(vector)}\")\n",
    "print(vector[:10])\n",
    "\n",
    "emb_1 = embedding_model.get_embeddings([\"What is the meaning of life?\"])\n",
    "emb_2 = embedding_model.get_embeddings([\"How does one spend their time well on Earth?\"])\n",
    "emb_3 = embedding_model.get_embeddings([\"Would you like a salad?\"])\n",
    "\n",
    "vec_1 = [emb_1[0].vector]\n",
    "vec_2 = [emb_2[0].vector]\n",
    "vec_3 = [emb_3[0].vector]\n",
    "\n",
    "print(cosine_similarity(vec_1, vec_2))\n",
    "print(cosine_similarity(vec_2, vec_3))\n",
    "print(cosine_similarity(vec_1, vec_3))\n",
    "\n",
    "in_1 = \"This kids play in the park.\"\n",
    "in_2 = \"The play was for the kids in the park\"\n",
    "\n",
    "in_pp_1 = [\"kids\", \"play\", \"park\"]\n",
    "in_pp_2 = [\"play\", \"kids\", \"park\"]\n",
    "\n",
    "embeddings_1 = [emb.values for emb in embedding_model.get_embeddings(in_pp_1)]\n",
    "emb_array_1 = np.stack(embeddings_1)\n",
    "print(emb_array_1)\n",
    "\n",
    "embeddings_2 = [emb.values for emb in embedding_model.get_embeddings(in_pp_2)]\n",
    "emb_array_2 = np.stack(embeddings_2)\n",
    "print(emb_array_2)\n",
    "\n",
    "emb_1_mean = emb_array_1.mean(axis=0)\n",
    "print(emb_1_mean.shape)\n",
    "\n",
    "emb_2_mean = emb_array_2.mean(axis=0)\n",
    "\n",
    "print(emb_1_mean[:4])\n",
    "print(emb_2_mean[:4])\n",
    "\n",
    "print(in_1)\n",
    "print(in_2)\n",
    "\n",
    "embedding_1 = embedding_model.get_embeddings([in_1])\n",
    "embedding_2 = embedding_model.get_embeddings([in_2])\n",
    "\n",
    "vector_1 = embedding_1[0].values\n",
    "print(vector_1[:4])\n",
    "vector_2 = embedding_2[0].values\n",
    "print(vector_2[:4])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
